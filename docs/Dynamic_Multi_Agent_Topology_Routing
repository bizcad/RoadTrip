# Dynamic Multi-Agent Topology Routing in Multi-Agent Systems
- link: https://www.youtube.com/watch?v=jWhnicSLdD4&t=1s
- date: February 5, 2026
- authors: Peing University, Georgia Institute of Technology, Southeast University, Chinua University
- paper: https://arxiv.org/abs/2602.00001
``` DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic
Matching
Yuxing Lu * 1 2 Yucheng Hu * 3 Xukai Zhao 4 Jiuxin Cao 3
from
1 Peking University, Beijing, China 
2 Georgia Institute of Technology, Atlanta, United States 
3 Southeast University
4 Tsinghua University. ```

## Transcript


0:00
Hello community. So great that you're back. Today we talk about the dynamic topology between a multi-EI agent
0:07
system. Now in my last video where I showed you how AI agents kill the
0:12
machine intelligence, we did have an absolute open communication structures
0:18
between our AI agents and I got a feedback from you. Can we optimize this?
0:23
What is the latest research here for the topology of multi-EI agents? So I found
0:29
a paper of today brand new concept and we will be working today on agentic
0:35
workflows and I will show you in this methodology it will demonstrate that the topology itself is what becomes now a
0:43
latent variable of the system that should be optimized at inference time.
0:50
Now you know classicalally we have a single agent system and we can run multiple single agent in parallel or if
0:57
you want to have the cooperation between five agents we as humans we can sign a
1:02
fixed topology to the system and then given here the particular roles and the particular competences and the
1:09
particular structures we just define how the system should interact but hey we
1:14
are in the time of AI so the latest research indicates what about EI is
1:20
doing the dynamic topology itself and not just at the beginning not just
1:26
somewhere in the middle but at every communication round. So EI builds a new
1:32
topology between the multiple agents every time there is a communication process every time we have a result and
1:39
we have to go to the next step. So this is the latest technology I could find
1:45
self if you want building topology by artificial intelligence itself.
1:52
How can you imagine this? I think this is a simple example. No, you have the bit. So the let's say we have an agent
1:58
that is coding. We have an agent that is testing. The coder agent shouts hey I need a test case for some edge
2:04
conditions and another agent says hey. the tester shouts, hey, I'm offering
2:10
edge case input for integer overflow. And then we have if you want here that
2:16
those two come together and we have a central switchboard and an EI coordinator that instantly connects now
2:23
the coder and the tester and now only these two agents are communicating for
2:29
their particular subtask. So they exchange now all the detailed data and
2:34
they too perform as a sub team here this subtask and let's say we have another AI
2:40
agent a mathematician who is working here on a proof but this AI agent hears
2:45
nothing about the communication process that is happening between the tester and the coder right so this is the new paper
2:55
peing university Georgia Institute of Technology Southeast University and Chinua University and they show us here
3:02
published February 5th, 2026 dynamic topology routing for multi-agent
3:08
reasoning via semantic matching. dynamic topology.
3:14
They set up dynamic topology, a multi- aent framework that dynamically rewires
3:19
here a sparse directed communication graph at each round via a semantic
3:26
matching between the agent natural language query and the key descriptors. But the query is simply the need and the
3:33
key is simply the offer that the agent has to the environment.
3:39
If you want the structural innovation of this new methodology is they build a dynamic computation graph that is
3:46
constructed now via a semantic key query matching. So you have that each agent
3:53
has now if you want two communication stream one is about the payload. So this
3:58
is the actual solution or the actual reasoning step and then we have on the second the meta data. So this is a a
4:06
lightweight natural language where the query so this is what the I say hey what
4:11
I need next for my job and the key this is what the eye says hey this is what I
4:17
just produced or communicated now as I told you we need a switchboard
4:22
we need a master intelligence a central intelligence and this is our semantic router
4:28
interestingly here the authors of this paper went here with an encoded transformer part only. So they went here
4:36
with an embadder, a bird system, a sentence bird system that now vectorizes here the keys and the queries. And guess
4:43
what? They just compute a similarity matrix. So they just went with a cosign
4:49
similarity to see if what is offered on a marketplace is exactly what is asked
4:55
for at this marketplace. Now I know what you're going to say. What a semantic routter this is all.
5:01
There's no world model. There's no deeper understanding. We just go here with a semantic
5:08
um similarity measure. Yes, but it is a first step. So let's have a look because
5:15
there's some beautiful insights with this particular study. Now and then we
5:20
have a gating. No, we have the adjacency matrix generated by applying here a certain threshold here to our cosine
5:27
similarity. So we say hey we do not accept everything. No. So we have a threshold toao and let's say for a
5:35
mathematical similarity I want to equals I don't know uh 0.5.
5:42
So whatever is above the threshold will get the directed edge and this edge is formed. If you are below the threshold
5:50
bad luck so next step is now a directed deck execution. Now all the messages
5:57
travel only along those particular edges and if the resulting graph is a directed
6:04
asyclic graph the messages are simply aggregated via a topological sort and if
6:10
it's cyclic you have a greedy horistic break that's is simply interrupting here the cycle.
6:17
Now it is rather simple from the idea. No, you have here a manager reviews here
6:23
the round result and decides to terminate everything but the manager also sets here unified current goals. So
6:31
whenever I as a human have here my query incoming the manager decides now the goals. Now there is a marketplace and
6:39
the marketplace we have agent A B C D and E and each agent just imagine is
6:44
shouting here a query and a key. The query is simply what it needs for the
6:49
job and key is what it offers here to be done. So let's say we have an agent that
6:56
is specialized in some data clearance and then we have an agent that is specialized in I don't know calculating
7:02
some similarity measures and another agent that is here whatever so you see
7:08
this is here now the if you want marketplace and now how we bring here
7:14
the buyer and the sellers together easy the idea as I told you here semantic
7:20
matching so we have the query embedding we embed this in a mamm atical space hopefully with the domain knowledge and
7:26
we have a key embedding. So here we have the if you want the seller and this is
7:32
here the demand then we have here simple dot product attention and if we are
7:38
above a certain threshold we can establish now an edge between some group
7:44
some subgroup of agent to perform a particular task in round one as I told
7:50
you two message channels manage a visible public channel and a private routed
7:56
communication channels Plus semantic matching model embeds the
8:01
description induces a decorated graph here for the particular subtask. And then you just go rounds. You have
8:09
your first round with agent A, C and E. Given this result, you go in the head
8:15
the round before where you had an interaction between five agent and before this you had a different
8:22
configuration, a different topology. So you have for your specific subtask the
8:28
decides which agent should perform what given the profile given the role and
8:34
design here a communication protocol and a decision structure all done by AI.
8:42
Now you might say what about the results of this system. This is now it gets interesting. Look, we have here four
8:49
task human evaluation, some computitional, some mathematic and some general mathematics. And now things get
8:56
interesting because we have four models. We have a Q138B,
9:01
a very old grandfather llama 38B. Then we have our GPT 120B and a MIMO version
9:09
2 flash. And now you see here an a pure LLM, not
9:14
as an agent, just as an LLM. But then we have here this single turn agent. Now
9:21
what does it mean? This means that we have four worker AI agents that generate now solutions in parallel without them
9:29
having a communication between the worker agent himself. So we have the
9:34
central boss the manager AI and four worker that do the job in parallel and
9:39
they just say hey this is my report and ciao. This is now the improvement. Have a look
9:45
at this. The first one we have an improvement here from 86 to 88. So plus 2%. With GPT
9:53
we have minus 2%. With a llama 3 we have plus 100%. And with a Q and three we
9:59
have plus 156%. So you see the smaller malls are real
10:06
sensitive if you have four copies of them. four workers that now are able to
10:12
maybe solve here the complex task for GPT 120B you lose performance and you're
10:19
going to have a look at this now the next one is interesting the next one is we have here four agents we have five
10:27
communication rounds and we have a random topology so a beautiful multi- aent system with a
10:35
random connectivity forced you to run for a fixed horizon for agent five rounds
10:40
Now you see that for the GPT 120B we continue to lose performance. So this
10:46
system in the particular task of human evaluation is not really the model that I would
10:53
choose. But look at an mathematical it has plus 45% or here omnimat it has plus
11:01
140%. So this is a highly askspecific performance where this particular system
11:08
GPT1 120B you can lose but you also can gain some performance. It is highly task
11:15
specific. So this means we really do not understand on what particular data GPT120B was trained or not trained or
11:23
what is the conflict of its pre-training data sets. Where it gets really interesting if we
11:30
go now to one of the latest multi- aent system that you are maybe familiar agent scope. So this is a reactbased multi-
11:38
aent framework using your broadcast topology also running here for the same
11:43
four agent five rounds. Now you see GPD 120B still minus
11:50
performance but look at the other marks. Now this is interesting.
11:56
Look at a QN38B. We started here real low because compare
12:02
this to the 120B and 18. But look, now we at 80 and the 120B is just at 92. So
12:11
the 8B model with agent scope had an improvement of 337%
12:18
just having here four agents communicating and trying to solve here the problem in a broadcast topology.
12:29
So this means we do have a real chance if we have a little tiny 8P model
12:36
that the improvement is so significant here that it's almost coming close here
12:42
to the GBD 12B. You see this here on this MAD benchmark
12:49
here we start here with an 8B even with a better performance here as an LLM but
12:55
then we just gain 66%. But for this particular task, GPT 120B
13:01
gains 160%. So we end up with a 120B it's 37 and the
13:08
8B it's 35. So these two figures are absolutely comparable. So it doesn't
13:15
matter if you start with only an 8B in this configuration. It seems a small
13:23
model has here the best potential to really here come close to the potential
13:28
here of huge models. This would mean we can run this locally
13:33
and we don't have to invest here in excessive rea memory to run a 120
13:39
billion free trainable parameter model which I found absolutely fascinating.
13:44
But now you might say yeah but what about the new methodology? Where is the new method? Well, of course here and as
13:51
you see it's bold. This means it outperforms everything in every category.
13:57
So if we have a dynamic topology where we have in each round an adaptation of
14:03
the topology of the communication graph between the I agent given the particular need in each round and we have five
14:10
rounds four agents. You see here now something interesting. Yeah. You see
14:16
suddenly the GPT1 120B comes close again with 98 to the original LLM output of
14:25
95. So does it make sense for this particular test here evaluation to use a
14:31
GPT1 120B in a 4 agent configuration? The data show us no.
14:38
However, look at the 8B model. We start at 18 as an LLM output and our dynamic
14:46
topology of our four agent gives us a performance that is close to 90.
14:53
This means here our topology of the agent routing here plus 390% performance
14:59
jump. This is nice. This is what I want to see here. So this is where the small
15:04
model can shine theoretically. Or look again at our mathematical task.
15:12
Here we have now that the 8B model, the Q138B has a performance in dynamic
15:18
topology of 51 and it outperforms as an 8B model. The
15:25
GPT 120B model that just achieves a 41.
15:31
But 8B model outperforms a 120B model in this new agent topology, the dynamic
15:38
agent topology. Now you might say hey but this looks like code and mathematics and you're
15:44
absolutely right because we do have to have verifiable reward structures. So this is not for open-ended question.
15:51
This is for when we can either code something and see if it's working or we do some mathematics and we know exactly
15:58
what is the correct mathematical solution to an equation. But anyway given this it shows us multi- aent
16:06
system or let's say an 8piece system can be really beautiful and yeah just
16:11
looking at llama 3 you see the difference here is so staggering so
16:16
please meter if you are watching where is llama 5 we need an open-source llama
16:22
5 real soon so super intelligence do something
16:28
oh yeah just between you and meh I have to tell you I I have no idea what is myo version two. So I went there and there
16:36
is January 8, 2026. This is by Xiaomi.
16:41
This is here a mixture of expert model with 39 billion total parameters here
16:47
when 15 billion active parameter. Real interesting. It has a multi-teer on
16:54
policy distillation. So I have to learn about this model. Imagine this is out now more than a month already and they
17:01
have not tested this model. But just look at the performance data. This looks really interesting and especially here
17:08
in mathematics it's absolutely on top shelf and here really
17:13
outperforming all other models here. So interesting. I discovered a new model.
17:21
Again this rewired communication is round specific. In each round we have a
17:28
different goal and the authors of the study show us here an example. They say listen in round one maybe our goal is to
17:35
define the initial approach and objective for the task. So if we have let's say four agents we have a
17:42
researcher a tester a designer and a developer. This is now the execution order that the master AI would decide.
17:49
Researcher developer designer tester. Then we do this. So we have round two.
17:54
We have now a different goal. Now our goal is to confirm the developer code passes here the specific dock string
18:01
test and the testers edge case. If confirmed then declare the project
18:07
complete. So we have a different communication structure, a different linear execution and then you see this
18:14
is just here to show you given you a specific task the eye decides here
18:20
hopefully it has the knowledge what is the right sequence of testing of
18:25
evaluation and so on. The prompt is simple. Just look at this.
18:33
This is here the manager, the boss agent prompt. No. And we have here the code generation. So you just tell here this
18:39
particular AI agent, hey listen, you are the manager and the workflow orchestrator. You decide if the task is
18:46
complete or the subtask is complete. You have a strict response format that is mandatory. You must output only a valid
18:53
JSON object with exactly those fields. Public content, private content. Then
18:59
you have the string required here for the query. The string for the keys is complete is a boolean value and the next
19:06
goal is simply a string critical rules primary focus string constraint. If you
19:11
see Python code analyze it from your rules perspective simple prompt and of course I have to
19:18
show you the generic worker the agent prompt here the template. Guess what?
19:23
This is it. So you see a very interesting communication topology now
19:29
that is done by AI but this this topology is of course based on the role
19:34
that you have. I told you the orders decided to go with four AI agent here in our ensemble. So they tested for code
19:42
generation task and they said those are the roles that we found the most helpful a developer a researcher a tester and a
19:50
designer and those are now the description the developer implement complete
19:56
runnable code if using classes provide independent function as entry point researcher identify the algorithms and
20:03
the time complexity output conclusion without derivation tester designer API
20:09
interfaces And then as I told you they went also for pure mathematical reasoning because
20:15
they need the verifiable rewards. Now they choose the role of the four
20:21
agent differently. We have now a problem parser, a solver, a verifier and a
20:27
manager. And you see here the primary responsibility and the core constraint for each of those roles.
20:35
So problem parts of course decompose the problem statement output must include
20:41
analysis known condition the target and a stepbystep plan. Now if you or the
20:48
agent fails here, no everything will be lost because if the agent has not the
20:53
intelligent or the knowledge to know exactly which conditions imply which
20:59
mathematical construct or which um theory you have to apply or which methodology you have to apply then you
21:07
cannot generate a step-by-step plan over mathematical derivation beautiful
21:13
provide the detailed step symbolic reasoning verify the Jack and the manager is just
21:19
responsible for the workflow orchestration. So you see you have
21:24
different roles and different topologies and just to show you another detail here
21:30
we have here the typical query descriptor and the typical key descriptor. Here are some examples. So
21:37
you see the parser says hey I need a problem statement to analyze the solver has here I need a problem analysis and a
21:43
solving plan verify and you get the idea. So you have clearly defined some
21:48
dependencies here already and then you have a dynamic routing.
21:55
Now if you want to go now a little bit deeper into the operational coding and
22:00
how it is really working. Let's do this. So this dynamic topology method is a
22:07
loop that consists here of five phases. Phase one single pulse interference and
22:12
the descriptor generation. Phase two the semantic graph induction. Phase three
22:18
the topological sequencing. Phase four the routing and the memory update of the agents. And phase five the manager
22:25
control with a multi-level feedback loop. Now you see that there's a lot of in the
22:32
m in the description here after methodology you find cyto code and I got the feedback from here from my viewers
22:39
hey cyto code it seems so complicated I hardly use it now I want to tell you
22:45
cyto code is your friend this gives you some deep insight into the real
22:51
operational methodology it is not yet that it is here a deep
22:57
code implementation ition but it gives you here the most essential elements here if you want to code this later and
23:05
if you take any I don't know cloud 4.5 if you have a beautiful cider code
23:10
algorithm defined it is much easier for an EI to really write the code do some
23:16
wipe coding because we have now a skeleton for the EI coder
23:23
so if you want py code condensed method represented now if you look at this this is a
23:28
screenshot from the study. Um this is something that I say okay but I decided
23:34
I will work with this. So I built here a single AI agent that is optimizing this.
23:41
If you think about if we have this multi- aent topology with the manager and our agents I told you it is like a
23:48
marketplace now. So my EI agent is with my task now if you want enters now a
23:54
very specific marketplace. Let's say it's for finance, for accounting, SAP or
23:59
for medical, whatever. And just imagine that this agent is now entering the marketplace and you have a lot of little
24:06
shops in this market. No. Now my agent goes shopping at the market and every
24:12
little um shopping place there is shouting out, hey, I have fresh bread. I
24:17
have fresh, I don't know, fishes. I have some old cheese. No. And then my agent
24:23
goes shopping at this mall. And more or less the same is happening now on the
24:28
level of agents if you want in this simplification. So therefore my little eye takes all of
24:35
this in and then it writes for me a newer code in my standard notation. So
24:43
you see it is real similar and I checked multiple systems and if you want I've
24:49
divorced I found is GPD 5.2 And two, it fails completely in this transformation process. And what I use is here a Gemini
24:56
model because this is here for my particular case for my particular soy
25:02
code interpretation the best model available. So you see I have not 29 lines. I just
25:08
have 27 lines. I have here for example I want in blue have my phases and I have
25:14
additional information here. What is it? Construct the local state. generate
25:19
output and the metadata embed here the descriptor normalize here the vectors and you see I want my formulas here in a
25:26
in a pretty form now so and some other things here so you see I have here a
25:32
transformation process therefore I have here a coherent system and then this is
25:38
the way that I if you want store here and I learn here my AI system to understand this and therefore if I
25:45
combine multiple paper I have more and more that I work here with those particular upside.
25:51
So let's do this here. As you see, it's not only that it writes the PO code, but
25:57
it also takes here the paper itself. And you see, if I have 10 Pyto codes per day
26:02
that I have to read and hopefully understand. My first problem is I have no idea about the mathematical notation
26:10
and about the parameter. What does it mean? SQI T. What does it mean? because
26:17
every order has a different interpretation of a parameter. So as you can see here I decided here that my EI
26:24
system just gives me here for each line of the prosider code exactly what are
26:29
the parameters. So I have here line six here the agent state. Ah I see this is
26:34
the agent state combines three elements. We have here row the state system prompt. This is the role. Then we have
26:41
the dynamic instruction for this specific round. And then we have the accumulated memory context. So you see
26:48
it just explains to me what are the parameter here in this parenthesis for me to be able to directly read here this
26:56
code. Then line seven explains to me here what are those parameters? what is
27:02
it exactly here as specified in this publication and then I'm able here to hopefully get
27:10
around and understand what is this new methodology and I also have that I ask you my very descriptor and give me an
27:17
example give me a very short example I just want to get a feeling what I'm dealing with here and if you have this
27:24
and I get this here for all the let's say 10 papers that I want to read per day I already get this if you want
27:31
simplification for me to faster understand so code. And now we go to here to topology
27:37
induction. This is now important. This is now really I want to explain you this methodology here on the code level. So
27:44
you see the Pytoo code is your friend. Phase two. Beautiful. So what is the
27:49
goal? Mapping the semantic intent to a directed graph structure. So the first
27:55
step as I told you in line 11 here is we do some embedding. So we take here a
28:00
pre-trained encoder transform architecture and I think I have 50 videos on a sentence bird structure. How
28:07
to code it, how to build the tokenizer, how to code it in I don't know how many different uh programming languages.
28:14
Great. So we have our sentence bird and then we map here the text descriptor here to a common vector space. Now you
28:23
know you have to train this vector space that it makes sense to place the vectors in this vector space based on their
28:30
semantic similarity. Then the next step is simply the normalization. All the vectors have to
28:37
be normalized. Now let's say an L2 normalization to allow for our goal
28:42
because what we want is we want to have here the semantic similarity and the easiest way to do this in a vector space
28:48
is a cosine similarity comparison. So here we have it. This is now if you want
28:53
the matching engine. This is here the routing logic. And this simply calculates you the alignment between the
28:59
agent need and what the other agents offer. Remember the marketplace when
29:05
here the need and the offer here semantically the closest. Of course you
29:12
might say yeah but a semantic similarity does not really mean because just imagine one is saying hey I need this
29:19
and the other agent says hey yeah I'm offering exactly this solution but you don't know if it is using here a
29:27
simplified mathematical formula it is doing a full integration on the phase space or it is just doing here I don't
29:35
know um iteration here on a quantum field theoretical fayman diagram that stops here at level three. So you have
29:43
no idea about the deeper methodology about the implementation about the limitation everything is missing here a
29:49
deeper understanding if we just go here for the semantic similarity but this is
29:55
it where we are then line 15 you have here the hard gating the threshold you
30:00
define yeah you as human you define the threshold no and then if you're above
30:05
great and if you're below you know so you see easy this is all that is here in
30:11
the line 9 to 16. This helps you to understand what is going on. So
30:16
therefore, epsido code can be your friend. Now phase three is now deterministic
30:23
message ordering. So what is the goal? Linear is the graph for the LLM context window. Since LLM reads sequentially,
30:30
the director graph must be flattened. Is this the optimal topology? No. But it is
30:35
a simplification that seems to work quite well. So let's go with this.
30:41
So if our graph is a directed as cyclic graph, beautiful just use the standard
30:46
topological sort. If it is not, if it is cyclic, use some greeduristic here to
30:52
break the cycle deterministically. This will ensure the reproducibility here of
30:57
our solution. And then we're already at phase four, the routing, the memory update
31:05
one. Beautiful. You understand? agent I identify its valid incoming neighbors
31:10
because as I told you we have now sub teams of agent I don't know A C and D
31:16
that work together as a subgroup now we have here the input filter and then we have the update equation here and you
31:23
see here exactly I understand what is everything here so and an explanation that the I writes to me the agent I only
31:31
receives private messages from the neighbors that are connected here in phase two all the other noises filtered
31:38
out. The subgroup is just focusing on its subtask and our sigma is aggregating
31:43
these messages in the strict order defined here in phase number three. So
31:49
this means our sigma here is simply the aggregation operator that concatenates the messages based on the relevant score
31:56
highest relevance first ensuring that the most critical context appears first
32:01
in the prompt. Simple a little bit of prompt engineering and this is already phase four and you
32:08
know phase five is simply here the manager control if you want a high level orchestration.
32:14
So manager pi observes here the global state consisting only of the task
32:20
context and the public messages. So doesn't care about the private technical details of the subgroup. We are now only
32:27
interested in the result of the subgroup if it's valued and how the result of the
32:32
subgroup come together to the main result. And now the manager decides okay
32:39
is the main result achieved then we have a stop decision one or zero and if it's
32:45
not um already here achieved then the manager will have to define a goal for
32:52
the next round. This is something beautiful here. So
32:57
this means it is up to the AI manager to the boss AI to decide when to stop. So
33:04
if you have simple problems, the manager might decide, hey, we found the solution after three rounds. If you have a real
33:12
complex problem, the manager might decide, hey, we have to let's go the
33:17
first 10 rounds and then decide at round 12 that this is now a result that looks
33:24
valid and outputs now this is the official result. So you have really a
33:29
complexity relevant decision by this boss manager here how
33:36
many rounds to go. I really like this. It is not that it is predefined but this
33:42
is a decision by the I itself. So therefore you see the topology is now a function of the state and the optimal
33:50
communication graph of our system is not static at all. So this is really the
33:56
latest publication I could find here the latest most let's say intelligent
34:01
solution by a self-arning AI itself. Of course, if you in the early rounds, this
34:07
requires you a more broader or some dense topology for the exploration. But
34:13
if you are in the later round after round 10 12, you require now some narrow
34:19
topology. You want to bring it here to really here what is here the final answer. You have the verification, you
34:26
have the formatting and you have now that everything converges here to a
34:31
single output. This gives us a beautiful new
34:36
interpretability of this coordination trace that is going on in our multi- aent system. And
34:43
because the edges are formed via explicit needs and offers here by our agents, we can record them have a
34:51
debugging process and not just an output where we see okay the result is incorrect but why now we understand if
34:59
the code generator fails. We can look now at the graph and see ah in round two the coder requested here whatever and
35:05
yeah this is exactly where it failed. So the EI debugging is now really
35:11
beautiful. So this means that this level of structure debugging let's call it structure debugging is impossible in a
35:17
blackbox multi- aent discussion. But now in this open graph structure we can
35:23
record it and we can have a beautiful debugging experience. Now of course this system has a lot of
35:29
limitations and let's just be clear and let's wise it.
35:36
The friction point is the dependence on the self description. The routing quality depends entirely on the agent's
35:43
ability to accurately describe its own needs and its offers. And if the MAL
35:49
doesn't even understand what is requested or what methodology
35:55
you would need for a certain complexity query and it is offering a a Newtonian
36:01
physics solution to something that would require I don't know a special relativity methodology, we have a
36:08
problem. It is also that the authors found sometimes the model the agents hallucinate the capability no but they
36:16
don't no they are unable to do this it's a pure hallucination and it will produce garbage and the router will still
36:23
prioritize this bad signal thereby poisoning here the receiving agent and
36:28
in turn than the complete network in also please notice and this I found
36:35
absolutely fascinating the hyperparameter tuning Remember we have this toao the similarity threshold that
36:43
we say okay we say the something is real semantically similar if it's above a certain threshold. Now during the
36:49
ablation studies here of this particular methodology they found you can go down as low as toao equals 0.3 and this will
36:58
work for code and you will get some sensitive code back that is that makes sense but toao equals 0.3 is not working
37:06
for mathematics at least 0.4 or 0.5 is needed for mathematics. So you have now
37:14
to put your threshold a little bit higher. you don't accept everything. So to find here this threshold would
37:21
require quite a lot of experimentation here but yeah if you get a better result
37:27
yeah I think it's worth the time no so in a general purpose system who would
37:32
tune now this toao of course you can write here short script and say just run over from toao equals 0.1 in steps of 0
37:41
whatever but is there a general logic that we can find that ani could execute
37:48
well what is our human interpretation. How do we humans decide where to put
37:54
here allocate here our specific threshold for our specific task? So there's a lot of methodology that we
38:00
need to develop here for the next kind of job multi- aent topology absolutely
38:07
fascinating. So manager EI agent agent agent agent four five agents and you see
38:14
the possibility to improve the performance is simply amazing. I showed
38:20
you the result if you have a GPT 120B or if you go down to an 8B model
38:26
performance jump for the 8B model is really what I would like to underline
38:32
here and show you this is important. We can run 8B local multi- aent system on
38:39
our local machine and achieve results where we normally have to pay you a
38:44
cloud provider. So why not utilize this knowledge and try it out yourself and
38:50
get much better result. I hope you enjoyed this video. Maybe I provided some new data. Maybe you
38:57
enjoyed it. Why not leave me a like, subscribe to my channel, become a member of my channel. Anyway, I hope to see you
39:03
in my next video.

## Summary and Analysis