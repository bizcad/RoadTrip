# Six practices to avoid failure
## Transcript

0:00
You can be great at prompting and you
0:02
can even be using the best models and
0:04
doing literally everything right and AI
0:07
will still quietly drop what you asked
0:10
for. Not edge cases, not polish core
0:13
requirements. That's the part nobody
0:15
warns you about. The failure mode is
0:18
silent. After thousands of hours
0:20
building with AI, coding, writing,
0:22
planning, six practices have survived.
0:26
Here's the first one, and it's the one I
0:29
would try first.
0:35
Most people, of course, type their
0:38
prompts, but when you type, you edit as
0:41
you go, right? You strip out the
0:43
tangents, the unnecessaries, the
0:45
uncertainties, the things you're not
0:46
really sure of. You want to feel
0:48
intelligent when you're typing this out,
0:49
and you really don't want to type too
0:51
much. But that messiness is exactly
0:54
where the intent lives. So, I stop
0:57
typing. I talk. I really want to be able
0:59
to do a quick look up for words. I want
1:01
to be able to search uh look up words,
1:03
find the etmology for them. Oh. Oh,
1:05
yeah. Uh I also need to be able to look
1:07
up slang very quickly. Be able to tell
1:09
what era that slang was from that should
1:11
be denoted quite clearly. Kind of meme
1:14
uh uh generated ideas. I really like
1:16
seeing first usage and derivations and
1:18
also kind of how it's changed over time.
1:21
So, I think that's kind of also an extra
1:23
important. And I want to be able to do
1:24
phrases. I want to be able to do idioms,
1:26
things like that. All of this should
1:28
kind of fit together in a puzzle. It
1:30
should look something like spotlight. I
1:32
should be able to bring it forward very
1:33
easily, very, very quickly. So now I
1:36
have thousands of words of kind of raw
1:38
thinking. If I just throw that at AI and
1:41
say build this, I get something kind of
1:43
shallow. The real unlock is what happens
1:46
next. You give this thinking piece a
1:50
place to live.
1:56
Okay, if you do all your thinking in
1:58
chat, you end up with kind of vibes, a
2:01
big long thread, kind of half decisions,
2:04
no real artifacts that are easy to get
2:06
out. Nothing that you can really easily
2:09
reuse except for that chat, of course.
2:12
And chat is ephemeral. Files are
2:15
durable. So, I stopped treating the
2:17
conversation as the work. I treat the
2:20
folder now as the work. Here's the
2:22
practice. You open a project folder,
2:24
start creating context right there. This
2:27
makes your work reusable. You can come
2:30
back next week. You can hand it to a
2:32
different context. You can hand it to a
2:34
future you. And this is not devspecific.
2:37
This is how I do everything with AI now,
2:40
including this video. Okay. What you're
2:42
about to see is the exact workflow that
2:44
I use to get started with all of my
2:46
videos and pretty much all of my other
2:49
work, which is pretty highly various,
2:51
and I'm sure it is for you as well.
2:52
Basically, we've started in a new
2:54
folder. I've just created a brand new
2:56
folder, then created four subfolders.
2:59
They don't have anything in them. I
3:00
currently have dropped something in.
3:01
We'll look at that in a second. But I do
3:04
create a Claude MD file. This claud file
3:06
is a simple guidance file that says the
3:09
content in is where I put stuff. This is
3:12
where the user comes in and puts content
3:14
into the system and the content out is
3:17
where the agent writes stuff. So as
3:19
we're writing new artifacts, what I
3:21
don't want is I don't want another agent
3:24
in the future to pick up artifacts from
3:26
the output file and be polluted. If I'm
3:29
trying to say, take a look at all the
3:30
stuff I've shared with you. Let's keep
3:32
working on that. It may read on its own
3:34
stuff. So if it reads from content out,
3:38
I want to do that very explicitly. I
3:40
want to say go read this file that's in
3:41
content out. So it'll just say this is a
3:44
place that agents should only write here
3:46
and should read from content in. That's
3:48
pretty much it. All right, so let's move
3:50
into the rest. So as you just saw, I
3:52
record what I call walks. This is me
3:55
clearly walking around [laughter]
3:57
just talking out loud and recording it
3:58
all. And then I transcribe it. So you
4:00
can even see this is literally how I
4:03
started this video. This was the walk
4:05
file that began this whole video. And
4:07
you can see how partial it is and how
4:09
many stammers I'm doing and stopping and
4:12
going back and forth. So, that's for
4:13
real. That's something I really do. And
4:15
as you can see, it's a very long
4:17
transcript of a big walk that I did just
4:20
talking through everything that I might
4:22
want to start covering. I really need to
4:24
dump as much as I can because what I've
4:27
got, that's the treasure. And then from
4:30
here, we're carving it down. So, this is
4:32
the raw marble that we've created. And
4:34
from here, I put this back into Claude
4:36
and said, "Hey, just take a look at this
4:37
file and tell me where you think we
4:39
are." All right, it comes back and says,
4:41
"Okay, this was pretty solid. You've got
4:43
a whole bunch of this information in
4:44
here. Some of the things that we kind of
4:46
need to push forward on." And that's
4:48
where it asked me questions the first
4:50
time around. Let me show you those real
4:51
quick. So, I'm sharing the WO1 questions
4:54
file with you. And this is just what it
4:56
came back with in chat the first time
4:57
around. and it said, "Oh, well, there's
4:59
some things that I think that we really
5:01
need to kind of follow up on and get
5:03
more understanding about. So, let me ask
5:05
you some questions." And I said, "Hold
5:07
up. Stop there. Remember, the chat is
5:10
not the thing that we're going for
5:11
here." So, I said, "Write all your
5:13
questions to a file and put it in the
5:15
content in call it walk one questions
5:17
and then I'll answer them." So, as you
5:19
might imagine, I created another file. I
5:22
simply came up here and said walk one
5:24
answer file, right? So this is the
5:27
answer file and as you can see it's a
5:29
big transcript another very large
5:31
transcript but what I'm doing here is
5:34
I'm telling it okay I'm recording an
5:35
addendum to the walk1 file I may be
5:38
reading the questions and answering them
5:39
at the same time and the first one is
5:41
what does brownfield process look like
5:43
and of course that's what this says what
5:45
does the brownfield process actually
5:47
look like that you work in so I went and
5:49
just recorded answers to everything and
5:52
then the next time I came back here I
5:53
could then say okay read through the
5:56
answers that I have, the questions and
5:57
the answers that I have. Now, you can
5:59
kind of contextualize. Let's move
6:01
forward from there. So, what you're
6:03
seeing is me use the operating system.
6:06
What we're doing is holding this folder
6:08
as really the source of truth. It's our
6:11
product. So, from there, I then say,
6:13
okay, I need you to create kind of an
6:15
outline for me. What's important here?
6:17
What's not important? And really, where
6:19
we started, had you looked at any of
6:20
this? It it is not the video that we
6:22
ended up with. it was much broader in
6:24
its original scope. And then working
6:26
with AI, it started teasing out a few of
6:28
the very important items that I said,
6:30
"Hold up. While you're coming up with
6:32
those different items, I want you to
6:34
start writing some files and content
6:36
out." So, every time it comes back with
6:37
a big list or has thoughts or has
6:39
concerns, I say, "Great. Write that out
6:41
as a file. Write that out as a file." It
6:43
sounds a little pedantic at some point,
6:45
but what happens is I end up with a
6:47
bunch of files here that I can index
6:49
back into at any time and say,"Great, I
6:51
want to talk a little bit more about
6:52
these questions you had, or you brought
6:54
up a really good angle over here that I
6:56
kind of want to lean into. Can you go
6:57
read more about what your thoughts
6:58
were?" Instead of making the
7:01
conversation that I have going be the
7:04
only direction that we can take, I'm
7:05
kind of creating a graph by using these
7:08
files at all times. And that brings us
7:10
about to this phase where we have
7:12
multiple scripts that have been written.
7:14
I have a full inventory of all the
7:16
topics that it could read out of my
7:18
original file and the things that I
7:20
thought I might want to share. And it's
7:22
really all my content, all my intent
7:24
that I put in in the beginning that
7:26
we're driving from and kind of editing
7:28
down. I'm now working with an editor.
7:30
It's also really worth saying I did
7:32
create I have a set of skills here
7:35
called vid skills. And inside of these
7:37
skills, I have a whole bunch of
7:38
different actions that I can take. And
7:40
those are very common actions on working
7:42
with scripting and brainstorming and
7:44
researching and a bunch of other things
7:46
that I've written as a skill set. That's
7:48
for a later date, but I do use that and
7:51
that's how I end up with these different
7:52
scripts and how the scripts all end up
7:54
with a format that I'm used to and that
7:56
I'm comfortable with and I can make
7:58
quick sense of. So that's the whole
8:00
process of how I work in this kind of
8:03
bare document or this bare folder that
8:05
we started with and just talk into it,
8:07
save it as a file, tell AI, read it,
8:09
what do you think? What else do we need?
8:11
This is the direction I think I'm going.
8:13
It asks questions. I answer questions. I
8:15
give it more context. When I come up
8:17
with more ideas, I'll create more walk
8:18
files, as you might imagine. So it just
8:20
keeps going and going. And many times I
8:22
end up with four or five different
8:23
script variants and I kind of have to
8:26
pick which direction I'm going to go
8:27
with any given video content. And that
8:30
really is the one that I end up shooting
8:31
really in the end. If you take anything
8:33
away from this one little tip here, like
8:36
I can't say how important this one is.
8:38
This one's number two behind talk
8:40
instead of type. This one's critically
8:42
important. The folder is the workspace.
8:45
Quit letting your chat experience be the
8:48
workspace. And if you need to carry
8:50
something forward, get it written down.
8:52
Create an artifact out of it. Those two
8:54
are critical. Create a folder and just
8:57
have a conversation there and keep
8:58
writing artifacts. So I use this same
9:01
basic process when I'm designing an
9:03
application and thinking about it and
9:05
considering it before I get into
9:07
building it. But once you have a folder
9:10
full of these kind of real artifacts and
9:12
PRDs or whatever else you might have,
9:15
the next step is kind of obvious. It's
9:16
something we've talked about many times.
9:18
You plan. And really, frankly, planning
9:22
is where AI quietly betrays you unless
9:24
you force it to prove the plan.
9:32
Okay, so here's the problem. AI planning
9:35
is confident and it also is always
9:38
willing to silently drop your
9:40
requirements. You might not know this,
9:42
but I've shown this in a previous video
9:43
where I did a lot of experimentation.
9:45
I've run these controlled experiments,
9:47
the same prompt, the same scope,
9:50
different runs, and I kept seeing the
9:52
same thing. Around 40% of what I asked
9:56
for was just gone. Now, these aren't
9:59
weird edge cases. These were actually
10:01
core features that were missing, like
10:02
the big fundamental features. So now I
10:05
do one thing almost every single time
10:08
that I plan. After the plan is
10:10
generated, I ask for it to verify
10:13
itself. And I know this feels redundant.
10:15
You're you're probably saying, "You just
10:17
did the plan. Why are you going to grade
10:19
yourself on your own plan? How could
10:21
that be any different than the plan you
10:23
just gave me?" But it works because it
10:26
forces a second pass with a different
10:28
posture. Coverage, not creativity. Okay,
10:31
here we are in a new project. I have an
10:34
initial PRD. It's a very big PRD, 300,
10:38
400 lines of pretty complex
10:40
requirements. And so what I'm going to
10:42
do is drop into planning mode and say
10:45
plan with initial PRD. Okay. And so here
10:48
we get with the plan as it finishes. But
10:51
if I scroll up, you can see this is a
10:53
really complete plan. This is a very
10:55
large plan for a very large PRD. So it
10:58
looks pretty good. But my gosh, it's
11:01
impossible for me to tell no matter how
11:03
diligent I am. It's impossible for me to
11:05
come through and make sure that
11:07
literally everything that I asked for is
11:09
in here. So here's what I do down at the
11:12
bottom in clawed code at least. I can
11:14
come down here and type something new
11:15
in. And this is a little trick. You can
11:18
do this any way you like. You can just
11:20
ask for this very very simply. But I
11:22
have a prompt that I like. So if I use
11:24
my prompt library, then I can bring this
11:27
up and I have a a prompt here that
11:30
basically says I want you to evaluate
11:32
the plan. So it's saying use the
11:34
original request per already in this
11:37
conversation as the source uh for each
11:39
major requirement. You can infer mark
11:41
covered partial missing that kind of
11:43
thing. So basically what it's doing is
11:44
it's saying look go look at what I asked
11:46
for. Go look at what you planned. Figure
11:48
out what you missed and score it and
11:51
then tell me that. Give me a report and
11:53
then use that report and replan. I know
11:56
it sounds obtuse but watch what this
11:58
does. Okay. And so here it is. It blows
12:01
me away every time. This one actually
12:03
did much better than generally it does.
12:05
But you can see it starts going through
12:07
each one of the different parts.
12:09
Spotlight pattern floating overlay. It
12:12
was covered. The global hotkey is
12:14
covered. But then you start noticing
12:16
click outside to dismiss the panel.
12:18
That's missing. And then you come down
12:20
and realize that we have the first
12:22
result is auto selected. That's not
12:24
mentioned in the plan anywhere. Uh
12:26
certain things are only partially
12:28
covered. So it does a great job of going
12:30
through the whole thing. If we scroll
12:31
down a little bit, it does create a
12:34
final coverage score. And like I said,
12:35
this one does a lot better. So, we're at
12:37
22% missed, which is still kind of
12:41
astonishing. And if you look down, it
12:42
has the top gaps by the impact. Clicking
12:44
outside to dismiss is the first thing.
12:46
Core dismissal path explicitly in PRD
12:49
missed entirely. Tab key navigation
12:51
between panels missed. First results,
12:54
auto selected on appear missed. Partial
12:56
immediate typing feedback missed.
12:58
explore mode, visual signal, uh kind of
13:01
the AI tone, the prompt engineering that
13:03
I put into it, all of these things,
13:05
related words, which was a really
13:07
important feature. PRD explicitly lists
13:10
it. It's not a feature in the plan.
13:13
There is a ton of stuff. And what did it
13:15
do? It went on and wrote another patched
13:17
plan. And if you're still worried about
13:19
it, obviously you can just run this
13:21
again. But every time I've run it again,
13:23
it gets to a 95 or better score. So, it
13:26
really does quite well at this point.
13:27
But this one, I can't tell you enough
13:29
how important it is to validate the
13:32
plan. And you have an AI right there
13:34
that loves validating things. So, let it
13:36
do it for you. Okay. So, we've solved a
13:38
little bit about planning. And let me
13:40
once again reinforce this is one extra
13:43
prompt. That's it. It's that simple. So,
13:46
now the plan is solid. But you'll hit a
13:48
new problem if you stay in one long
13:50
conversation. Your instructions begin to
13:52
decay. Which leads us to practice four.
13:55
This one's really easy.
14:02
Okay, so this one might feel a little
14:04
bit counterintuitive to some people
14:06
because it feels like you might be
14:08
throwing progress away, but the longer a
14:11
conversation gets, the weaker your
14:13
instructions become. So, we saw this
14:16
clawed MD file in one of these. These
14:18
are like the rules that are preloaded
14:20
into your context, your kind of do it
14:22
this way, your style, your testing
14:24
expectations or whatever it might be.
14:26
Like we said, don't write into this
14:27
folder, read into this folder, that kind
14:29
of stuff, all of that is injected at the
14:32
beginning of a context. So when you
14:33
start a new chat, but that starts to
14:36
fade. This is a classic pattern. You
14:39
start the session like run tests before
14:41
you tell me you're done and two hours
14:44
later it confidently is telling you that
14:46
it's done without running anything. Have
14:48
you seen that? I know I've seen it again
14:50
and again. It's not because it's
14:52
malicious. It's because the context is
14:54
decaying. So the more that's in there,
14:57
the farther away essentially those
14:59
initial kind of instructions really are.
15:03
So I clear the context at feature
15:05
request level. So a new unit of work
15:07
gets a fresh context. That's a really
15:10
important concept. And here's the rule
15:12
that changed everything for me. If I
15:14
need something to survive across
15:16
contexts, I don't hope that the model
15:19
remembers it. I write a document. You
15:21
saw me doing this earlier. That's what
15:23
the folder technique is really doing.
15:25
It's making memory external and it keeps
15:28
the work sharp. And once you're clearing
15:31
context, verifying plans, and working
15:33
from artifacts, you're set up for the
15:35
biggest unlock, walking away.
15:43
Okay, so most people hit the same
15:45
ceiling with AI. They become a
15:47
babysitter. They're not building,
15:50
they're supervising. And we all know
15:51
there's going to be some supervision,
15:53
but sitting there approving things,
15:55
switching tabs, checking progress,
15:57
context switching all day long, it's
15:59
exhausting. So, I wanted a different
16:02
posture. I wanted to hand off work and
16:05
get it done and then come back when it
16:07
was finished. So, I built a system
16:09
called do work. The headline isn't
16:11
autonomous. The headline is it's
16:14
autonomous and traceable. Because
16:16
autonomy without traceability
16:18
is really just chaos. If you can't
16:21
answer what's changed and why did it
16:23
change and where did it come from,
16:25
you're going to be scared to let it run.
16:27
Traceability is what buys you
16:29
confidence. Confidence is what buys you
16:32
time. Okay, we're going to be sharing
16:34
this little application that you've seen
16:35
me talking about and you've seen the PRD
16:37
for and the plan and a bunch of other
16:39
things. It's an application called Word
16:41
Light and it really is Spotlight for
16:42
words and wonder and that sort of thing.
16:44
And I'm going to show you the moment
16:46
that made this click for me. Okay. So,
16:49
when I'm selecting an item, I see that
16:51
there's etmology, but I'd really like
16:53
that to be formatted a little bit
16:54
better. It's starting to look good, but
16:56
there's just this big runon of all the
16:59
information, and it's in italics. And
17:01
then also, as I quick click between
17:04
items, I'll notice that the explore
17:06
items are not updating relative to my
17:08
selection. So, it kind of feels like if
17:10
I'm on a slang term or something like
17:12
that, you might have different explore
17:13
items. I understand that we have slang
17:15
multiple times. In fact, I'll even take
17:17
a screenshot and show you that on the
17:19
tiles themselves, we have slang twice.
17:22
So, I can show you that I used the slash
17:25
command, but I can also see that it's a
17:27
slang definition. So, I don't know. I
17:30
think that we need to improve that in
17:32
some way. I use a system that I built a
17:36
a skill called do work. Now, do work
17:39
comes up when you type in do work. And
17:42
you'll see that I can either run the do
17:44
work, capture new tasks, verify the
17:47
information very much like we just
17:49
verified our plan, um do a cleanup or
17:52
check for versions to see if there's
17:53
updates. Okay, so that's kind of the the
17:55
shape of this. But what it can do is
17:58
kind of amazing. So what I'm going to do
18:00
is I'm just going to paste in all of
18:01
that diet tribe that I just dropped in
18:03
and let it cook on it for a second. All
18:05
right, it comes back and it tells us
18:06
that it is a request 68 or user request
18:10
19. It tells us it's a complex request
18:12
with a lot of distinct features and
18:14
things of that nature. Here are the
18:16
different five items that it it
18:18
mentioned up front. And what it's going
18:20
to start doing is creating user request
18:22
documents in here that are related to
18:25
what I asked for. So if we take a look
18:27
at the input, then you'll see this is
18:30
what I said. It is saving the full
18:32
verbatim input information here. It is
18:35
also kind of simplifying it up here so
18:37
that it can understand it. But this is
18:39
all within the project now. So what I
18:41
asked for is codified somewhere. It
18:44
starts creating requirements documents
18:46
here that are all related to this user
18:49
request. We're on user request 19. If we
18:51
look at the etmology formatting, you'll
18:53
notice that it's related to the user
18:55
request 19. And so what it's starting to
18:57
do is kind of tie all these moving parts
18:59
together in a meaningful way. But most
19:02
important is it's creating independent
19:04
requests, verifiable requests against
19:07
what I asked for in the first place. So
19:09
now we can come down this and say okay
19:11
did we get everything? And in fact I
19:13
showed you you can do if you really
19:15
wanted to do work verify and what it
19:17
will do is essentially what we did last
19:19
time. It's kind of baked in. It'll look
19:21
at the last uh user request. It'll
19:24
evaluate the actual user request because
19:26
it has it. Remember it saved it as a
19:28
file. And then it'll look through all of
19:30
the independent requests to make sure
19:31
that they have the right nuance and
19:33
everything else inside of them. This is
19:35
everything that I've just showed you in
19:37
one place happening all at once. I am
19:40
not saying that this do work thing is
19:42
the absolute answer in the future. It's
19:44
got some challenges in the way that you
19:46
have to use it. It's pretty simple to
19:48
use, but it really does everything that
19:50
I'm trying to hand off here. So, if I
19:52
scroll back through that verify, you can
19:54
even see we got 88% confidence just from
19:57
this process. Um, and you can see where
20:00
it started falling over. It gives us
20:02
some interesting information about what
20:04
important items and what minor items it
20:06
missed, what recommendations it has. And
20:09
all I have to do is say yes, cuz it's
20:11
asking me, do you want me to apply these
20:12
fixes to these wreck files? Yes. And
20:15
move on. Okay, it came back and it says,
20:18
okay, we've we've revised our confidence
20:20
score to 93%, but the remaining gap is
20:22
the uncaptured screenshot. We can look
20:24
at the live UI to do that if you like or
20:27
I can just paste the screenshot in here
20:29
and I can say, would this help? Okay, so
20:31
that's fantastic. We have all of these
20:33
items over here that are just sitting
20:35
there waiting to be worked on. And then
20:37
the other half of this really takes over
20:39
when you do work run. What it starts to
20:42
do is it just simply picks the first
20:45
item out of this list that hasn't been
20:47
claimed. It moves it into working. It
20:50
completes it in its own subcontext.
20:52
Remember, we want to clear context
20:53
whenever we start new feature
20:55
development. This is feature. This is
20:57
not independent kind of uh little tasks.
21:00
This is not the smallest element that
21:02
each one of these requests are. These
21:04
are combined kind of features that make
21:06
sense together. It's going to do that
21:08
feature all in one context so that that
21:10
helps and makes sense. And then it's
21:12
going to throw that away, return back to
21:14
the main loop and cloud code. Cloud code
21:16
will say, "Okay, are there more?" Yes.
21:19
Let me take that new one, throw it into
21:21
a brand new context again, and continue
21:23
working. I've had this working for
21:25
multiple hours in a row fully
21:27
successfully. So, this allows me to
21:30
actually walk away. And that's really
21:31
the lesson that we're going for here.
21:33
All right. I've got to share one other
21:34
thing with you because this actually is
21:37
a major unlock. This one's specific to
21:39
this do work process, but I need to
21:41
share it because if you come up with
21:43
your own process and want to come up
21:44
with your own workflow, here is one
21:46
thing that I would highly advise that
21:47
you add to it. If we take a look at
21:50
previous changes, so these are all the
21:51
commits. After each one of these
21:53
requests is complete, a commit uh is
21:56
created with context around that change
21:59
so that you can see all of my previous
22:01
requests. Now, inside of that request is
22:04
all of the information that was asked
22:06
for. Also, all of the supporting files,
22:08
as you as you noticed before, are all
22:11
being checked in. So, anything can go in
22:13
and take a look at what the do work
22:14
request was and when it fell over. Many
22:17
times, I'll get to a place to where
22:19
something regresses or something wasn't
22:21
quite done the way that I thought it was
22:23
initially, and I come back and tell it,
22:25
I feel like I have a regression or a bug
22:27
here. I was asking for this a little
22:29
while ago, and now it's no longer doing
22:31
it. And what I've seen Claude do is it
22:34
will crawl through all of this git
22:35
history saying, "Oh, well, let's find
22:37
out where that was asked for because you
22:39
can see these commit statements all have
22:41
really complete kind of definitions on
22:43
them and it finds the right commit and
22:45
says, "Oh, this is when it was
22:46
requested. Let's move forward and see if
22:48
anything else changed that file. Oh, it
22:50
was regressed at this point. We need to
22:52
put a test in for it." It is really
22:54
self-solving in a lot of ways. And why?
22:57
It's because it has enough information
22:59
to be able to trace all of this.
23:00
Remember traceability we were talking
23:02
about? If it can't tell when it was
23:04
asked for, when it was changed, it can't
23:06
tell what's going wrong and why it keeps
23:08
changing. You give it that much
23:10
information, it can keep track of things
23:12
for you. Okay? And here's the part about
23:14
that that surprises me. Once you have
23:16
autonomy, you start noticing all the
23:19
little frictions that you've been
23:20
tolerating. And then you realize
23:22
something with AI, the bar for building
23:25
your own tools is nearly on the floor.
23:28
That's the last practice.
23:35
Okay. So, off-the-shelf tools are
23:38
generic. They're built for everyone,
23:39
which means they're built perfectly
23:42
basically for none of us, right? So, if
23:45
something in your workflow is irritating
23:47
you, build the fix. A slash command, a
23:51
tiny script, a skill, a hook. Maybe
23:54
you've heard it as we've been building
23:56
that completion sound that I have that
23:59
when the builder finishes doing
24:01
something, it comes back and tells me
24:03
that was a tiny tool that I built. It's
24:06
not impressive software. It's just a
24:08
missing ergonomic that I wanted. So, I
24:11
built it. And once you start doing this,
24:13
it compounds. Every little friction
24:15
becomes an opportunity to smooth the
24:17
system. This is the meta point of the
24:20
whole video. Every practice you just
24:22
saw, the walks, the folder, the
24:25
verification prompt, the autonomous
24:28
loop, these are not tips. They're things
24:31
I built, tested, and threw away and then
24:34
rebuilt until they survived. The
24:37
workflow is a product, and it gets
24:39
better the same way your products get
24:42
better. You iterate. Okay, I'm not
24:44
saying this is the one true way to work
24:46
with AI. I I don't believe that at all.
24:48
Different people have very different
24:50
constraints, different roles, different
24:52
tolerances. What I am saying is after a
24:55
lot of experimentation, these are the
24:57
practices that have stayed for me. So if
25:00
you haven't tried them, try one. Don't
25:01
adopt all six of them. Just pick one
25:03
lever and pull. Six practices. Talk
25:06
first. Give AI a place to think with
25:09
you. Verify the plan. Clear context
25:12
constantly. Automate and walk away. And
25:14
build your own tools. That for me is
25:17
what survived. If you want the voice to
25:20
text deep dive, subscribe. That's maybe
25:23
the next one or very soon. And if this
25:25
helped, I'd love to know which practice
25:27
you're going to try out first or really
25:29
tell me some of your practices. All
25:31
right. Really, I appreciate you being
25:33
here. Thanks for coming along for the
25:34
ride and I'll see you in the next